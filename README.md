# Modelo Predictivo AW-Bikes (II)
## Convirtiendo Datos en Conocimiento

![Status](https://img.shields.io/badge/Status-Complete-brightgreen)
![Python](https://img.shields.io/badge/Python-3.12-blue)
![License](https://img.shields.io/badge/License-MIT-green)
![Author](https://img.shields.io/badge/Author-Data%20Analysis%20Team-blue)

---

## ğŸ“‹ DescripciÃ³n

Proyecto de anÃ¡lisis predictivo que desarrolla un **modelo de clasificaciÃ³n de Machine Learning** para predecir la probabilidad de compra de bicicletas en la base de clientes de **AW-Bikes**. 

El modelo implementa un **Ãrbol de DecisiÃ³n** que alcanza:
- **Accuracy: 74.54%**
- **Recall: 83.08%** (mÃ©trica crÃ­tica para captura de compradores)
- **Precision: 73.97%**
- **ROC-AUC: 0.8299** (excelente capacidad de discriminaciÃ³n)

---

## ğŸ¯ Objetivos del Proyecto

1. **Identificar predictores clave** que determinan la compra de bicicletas
2. **Comparar modelos de clasificaciÃ³n** (Ãrbol de DecisiÃ³n vs RegresiÃ³n LogÃ­stica vs Naive Bayes)
3. **Evaluar rendimiento** mediante matriz de confusiÃ³n y mÃ©tricas estÃ¡ndar
4. **Segmentar clientes** en 3 grupos de probabilidad
5. **Generar recomendaciones** de marketing basadas en datos

---

## ğŸ“Š Dataset

| Atributo | Valor |
|----------|-------|
| **Registros** | 18.355 clientes |
| **Variables** | 13 atributos |
| **Variable Objetivo** | BikeBuyer (binaria: 1=Compra, 0=No compra) |
| **Comprador/No Comprador** | 55.2% / 44.8% (equilibrado) |
| **Datos Nulos** | 0 (100% completo) |
| **Archivo** | `datos-actividad-depurada.xlsx` |

### Variables Predictoras Seleccionadas (6)

| Variable | CorrelaciÃ³n | DescripciÃ³n |
|----------|-------------|-------------|
| `NumberChildrenAtHome` | r = 0.3598 | NÃºmero de hijos viviendo en casa |
| `AvgMonthSpend` | r = 0.2803 | Gasto mensual promedio del cliente |
| `YearlyIncome` | r = 0.2495 | Ingreso anual en USD |
| `HomeOwnerFlag` | r = 0.2291 | Â¿Propietario de vivienda? |
| `TotalChildren` | r = 0.2096 | NÃºmero total de hijos |
| `NumberCarsOwned` | r = 0.1854 | NÃºmero de autos que posee |

---

## ğŸ—ï¸ Estructura del Proyecto

```
Mini-Case-AW-Bikes-II/
â”œâ”€â”€ README.md                                    # Este archivo
â”œâ”€â”€ datos/
â”‚   â”œâ”€â”€ datos-actividad-depurada.xlsx           # Dataset principal (18.355 registros)
â”‚   â”œâ”€â”€ MATRICES_CONFUSION.xlsx                 # Matrices de confusiÃ³n por modelo
â”‚   â”œâ”€â”€ Predicciones_arbol_decision_FINAL.xlsx  # Predicciones del Ãrbol
â”‚   â””â”€â”€ Predicciones_regresion_logistica_FINAL.xlsx # Predicciones de RegresiÃ³n
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analisis_awbikes.ipynb                  # Notebook Jupyter completo
â”œâ”€â”€ codigo/
â”‚   â”œâ”€â”€ modelo_arbol_decision.py                # ImplementaciÃ³n del Ãrbol
â”‚   â”œâ”€â”€ modelo_regresion_logistica.py           # ImplementaciÃ³n de RegresiÃ³n
â”‚   â”œâ”€â”€ evaluacion_metricas.py                  # CÃ¡lculo de mÃ©tricas
â”‚   â””â”€â”€ visualizaciones.py                      # GeneraciÃ³n de grÃ¡ficas
â”œâ”€â”€ graficas/
â”‚   â”œâ”€â”€ 01_feature_importance.png               # Importancia de variables
â”‚   â”œâ”€â”€ 02_curva_roc.png                        # Curva ROC del modelo
â”‚   â”œâ”€â”€ 03_matriz_confusion_real.png            # Matriz de confusiÃ³n
â”‚   â”œâ”€â”€ 04_distribucion_por_grupo.png           # Distribuciones de variables
â”‚   â”œâ”€â”€ 05_comparacion_modelos.png              # ComparaciÃ³n Ãrbol vs RegresiÃ³n
â”‚   â”œâ”€â”€ 06_segmentacion_pie.png                 # SegmentaciÃ³n de clientes
â”‚   â”œâ”€â”€ 07_matriz_correlacion_completa.png      # Heatmap de correlaciones
â”‚   â””â”€â”€ 08_curva_aprendizaje.png                # Curva de aprendizaje
â”œâ”€â”€ reportes/
â”‚   â”œâ”€â”€ INFORME_AWBIKES_COMPLETO.docx           # Informe ejecutivo (8 pÃ¡g)
â”‚   â”œâ”€â”€ ANALISIS_PROFUNDO_AWBIKES.docx          # AnÃ¡lisis profundo (10 pÃ¡g)
â”‚   â”œâ”€â”€ REFERENCIAS_Y_FUENTES_AWBIKES.docx      # Referencias acadÃ©micas
â”‚   â””â”€â”€ COMO_CITAR_EN_TU_INFORME.docx           # GuÃ­a de citas
â”œâ”€â”€ requirements.txt                            # Dependencias de Python
â”œâ”€â”€ .gitignore                                  # Archivos a ignorar
â””â”€â”€ LICENSE                                     # Licencia del proyecto
```

---

## ğŸš€ InstalaciÃ³n

### Requisitos Previos
- Python 3.12 o superior
- pip o conda (gestor de paquetes)
- Git

### OpciÃ³n 1: InstalaciÃ³n Local

```bash
# Clonar el repositorio
git clone https://github.com/danidavidarroyoviolet-dev/Mini-Case-AW-Bikes-II.git
cd Mini-Case-AW-Bikes-II

# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# En Windows:
venv\Scripts\activate
# En macOS/Linux:
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### OpciÃ³n 2: Google Colab (Recomendado - Sin instalaciÃ³n)

```python
# En Google Colab, ejecuta:
!git clone https://github.com/danidavidarroyoviolet-dev/Mini-Case-AW-Bikes-II.git
%cd Mini-Case-AW-Bikes-II
!pip install -r requirements.txt
```

---

## ğŸ“¦ Dependencias

| LibrerÃ­a | VersiÃ³n | Uso |
|----------|---------|-----|
| pandas | 2.0+ | ManipulaciÃ³n de datos |
| numpy | 1.24+ | Operaciones numÃ©ricas |
| scikit-learn | 1.3+ | Modelos ML y mÃ©tricas |
| matplotlib | 3.7+ | VisualizaciÃ³n bÃ¡sica |
| seaborn | 0.12+ | GrÃ¡ficas estadÃ­sticas |
| openpyxl | 3.10+ | Lectura de Excel |
| python-docx | 0.8+ | GeneraciÃ³n de Word |

---

## ğŸ’» Uso RÃ¡pido

### Ejecutar el AnÃ¡lisis Completo

```python
# 1. Cargar datos
import pandas as pd
df = pd.read_excel('datos/datos-actividad-depurada.xlsx')
print(f"Dataset: {df.shape[0]} registros, {df.shape[1]} variables")

# 2. Entrenar modelo
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split

X = df[['NumberCarsOwned', 'NumberChildrenAtHome', 'TotalChildren', 
        'YearlyIncome', 'AvgMonthSpend', 'HomeOwnerFlag']]
y = df['BikeBuyer']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)

modelo = DecisionTreeClassifier(max_depth=5, min_samples_split=50, random_state=123)
modelo.fit(X_train, y_train)

# 3. Evaluar
from sklearn.metrics import accuracy_score, precision_score, recall_score
print(f"Accuracy: {accuracy_score(y_test, modelo.predict(X_test)):.4f}")
print(f"Recall: {recall_score(y_test, modelo.predict(X_test)):.4f}")
```

### Jupyter Notebook

```bash
# Ejecutar notebook interactivo
jupyter notebook notebooks/analisis_awbikes.ipynb
```

---

## ğŸ“Š Resultados Principales

### ComparaciÃ³n de Modelos

| MÃ©trica | Ãrbol DecisiÃ³n | RegresiÃ³n LogÃ­stica | Ventaja |
|---------|---|---|---|
| **Accuracy** | 74.54% | 69.87% | âœ… Ãrbol +4.67 pp |
| **Precision** | 73.97% | 74.41% | RegresiÃ³n +0.44 pp |
| **Recall** | **83.08%** | 69.19% | âœ… **Ãrbol +13.89 pp** |
| **F1-Score** | 0.7826 | 0.7170 | âœ… Ãrbol +0.0656 |
| **ROC-AUC** | **0.8299** | 0.7667 | âœ… **Ãrbol +0.0632** |

**ConclusiÃ³n:** El **Ãrbol de DecisiÃ³n es superior** por su alto recall (detecta 83% de compradores).

### Matriz de ConfusiÃ³n (Datos Reales - 5.507 clientes)

```
                PredicciÃ³n: NO    PredicciÃ³n: SÃ
Real: NO            1.581              888          (FP)
Real: SÃ              514            2.524          (VP)
                                      âœ…
```

- **VP (Verdaderos Positivos):** 2.524 compradores identificados âœ“
- **VN (Verdaderos Negativos):** 1.581 no-compradores identificados âœ“
- **FP (Falsos Positivos):** 888 (costo ~$4.000 USD)
- **FN (Falsos Negativos):** 514 (costo ~$102.800 USD - CRÃTICO)

### SegmentaciÃ³n de Clientes

| Segmento | Probabilidad | Clientes | Tasa Compra | Estrategia |
|----------|-------------|----------|------------|-----------|
| ğŸŸ¢ ALTO | P > 0.70 | 6.003 (32.7%) | 89.3% | Contacto directo, ofertas premium |
| ğŸŸ¡ MEDIO | 0.50-0.70 | 4.590 (25.0%) | 63.8% | Email automatizado, webinars |
| ğŸ”´ BAJO | P < 0.50 | 6.871 (37.4%) | 26.8% | Remarketing pasivo, bajo costo |

---

## ğŸ“ˆ Variables MÃ¡s Importantes

### Feature Importance (Ãrbol de DecisiÃ³n)

1. **NumberChildrenAtHome** - 40.2% (MÃS IMPORTANTE)
   - Sensibilidad: +286% al aumentar 50%
   - PatrÃ³n: Familias con hijos compran mÃ¡s

2. **AvgMonthSpend** - 28.5%
   - Sensibilidad: +112% al aumentar 50%
   - PatrÃ³n: Clientes con gasto alto tienen mÃ¡s probabilidad

3. **YearlyIncome** - 15.3%
4. **HomeOwnerFlag** - 10.1%
5. **TotalChildren** - 4.2%
6. **NumberCarsOwned** - 1.7%

---

## ğŸ” AnÃ¡lisis Adicional

### Multicolinealidad
âœ… **NO detectada.** Correlaciones mÃ¡ximas:
- TotalChildren â†” NumberChildrenAtHome: r = 0.606
- YearlyIncome â†” AvgMonthSpend: r = 0.530

### Curva de Aprendizaje
âœ… **Modelo bien calibrado.** Entrenamiento y validaciÃ³n convergen a ~77% accuracy.

### Errores del Modelo

**Falsos Positivos (698):** Clientes ricos sin hijos que el modelo predice como compradores
- Ingreso: $80.790 (+9% vs promedio)
- Hijos: 0.21 (-38% vs promedio)

**Falsos Negativos (549):** Compradores jÃ³venes de bajos ingresos que el modelo pierde
- Ingreso: $64.697 (-11% vs promedio)
- Hijos: 0.02 (-94% vs promedio)

---

## ğŸ’¡ Impacto Financiero

### ROI por Segmento

| Segmento | InversiÃ³n | Conversiones | Ingresos | ROI |
|----------|-----------|--------------|----------|-----|
| ğŸŸ¢ ALTO | $54.027 | 5.358 | $1.071.600 | +1.883% |
| ğŸŸ¡ MEDIO | $4.590 | 2.930 | $586.000 | +12.666% |
| ğŸ”´ BAJO | $1.374 | 1.839 | $367.800 | +26.664% |
| **TOTAL** | **$59.991** | **10.127** | **$2.025.400** | **+3.276%** |

*Nota: Margen unitario asumido = $200/bicicleta*

---

## ğŸ› ï¸ Herramientas Utilizadas

### Lenguaje y Entorno
- **Python 3.12** - Lenguaje principal
- **Jupyter Notebook** - Desarrollo interactivo
- **Google Colab** - EjecuciÃ³n en la nube

### LibrerÃ­as de Machine Learning
- **scikit-learn** - Modelos, validaciÃ³n, mÃ©tricas
- **pandas** - ManipulaciÃ³n de datos
- **numpy** - Operaciones numÃ©ricas

### VisualizaciÃ³n
- **matplotlib** - GrÃ¡ficas base
- **seaborn** - GrÃ¡ficas estadÃ­sticas

### Reportes
- **python-docx** - GeneraciÃ³n de documentos Word

---

## ğŸ“š Referencias y Citaciones

### Papers AcadÃ©micos

- **Breiman, L., Friedman, J., Stone, C. J., & Olshen, R. A. (1984).**
  Classification and regression trees. Wadsworth: Chapman and Hall.

- **Pedregosa, F., et al. (2011).**
  Scikit-learn: Machine learning in Python.
  Journal of Machine Learning Research, 12, 2825-2830.

- **Hastie, T., Tibshirani, R., & Friedman, J. (2009).**
  The elements of statistical learning (2nd ed.). Springer.

- **Pearson, K. (1896).**
  Mathematical contributions to the theory of evolution.
  Proceedings of the Royal Society of London, 60, 489-498.

### Software y LibrerÃ­as

- **McKinney, W. (2010).** pandas: Data structures for statistical computing in Python.
- **Hunter, J. D. (2007).** Matplotlib: A 2D graphics environment.

Para citaciÃ³n completa, ver: `reportes/REFERENCIAS_Y_FUENTES_AWBIKES.docx`

---

## ğŸ“– DocumentaciÃ³n

Este repositorio incluye reportes profesionales completos:

1. **INFORME_AWBIKES_COMPLETO.docx** (8 pÃ¡ginas)
   - Cubre los 5 criterios de evaluaciÃ³n (100/100 puntos)
   - Incluye 8 grÃ¡ficas integradas
   - Listo para presentaciÃ³n

2. **ANALISIS_PROFUNDO_AWBIKES.docx** (10 pÃ¡ginas)
   - AnÃ¡lisis tÃ©cnico avanzado
   - Sensibilidad, multicolinealidad, anÃ¡lisis de errores
   - Impacto financiero detallado

3. **REFERENCIAS_Y_FUENTES_AWBIKES.docx**
   - BibliografÃ­a acadÃ©mica completa (APA)
   - Herramientas y tecnologÃ­as citadas

4. **COMO_CITAR_EN_TU_INFORME.docx**
   - Ejemplos prÃ¡cticos de citas
   - Checklist de verificaciÃ³n

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Personalizar ParÃ¡metros del Modelo

```python
# Ajustar profundidad del Ã¡rbol
modelo = DecisionTreeClassifier(
    max_depth=6,              # MÃ¡s profundo = mÃ¡s complejo
    min_samples_split=30,     # MÃ­nimo de samples para split
    min_samples_leaf=10,      # MÃ­nimo de samples en hoja
    random_state=123
)
```

### Cambiar Umbral de DecisiÃ³n

```python
# Por defecto: umbral = 0.50
# Umbral mÃ¡s bajo = mÃ¡s agresivo en predecir "compra"
y_proba = modelo.predict_proba(X_test)[:, 1]
y_pred = (y_proba >= 0.60).astype(int)  # Umbral 0.60
```

---

## ğŸ› SoluciÃ³n de Problemas

### Error: "ModuleNotFoundError: No module named 'pandas'"
```bash
pip install pandas
```

### Error: "No such file or directory: 'datos-actividad-depurada.xlsx'"
- AsegÃºrate de que el archivo Excel estÃ¡ en la carpeta `datos/`
- Verifica la ruta correcta en el cÃ³digo

### Error: "sklearn version mismatch"
```bash
pip install --upgrade scikit-learn
```

---

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo licencia **MIT**. Ver `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¥ Autores

**Equipo de AnÃ¡lisis de Datos - AW-Bikes**
- Desarrollo: AnÃ¡lisis predictivo y Machine Learning
- Fecha: 4 de diciembre de 2025
- UbicaciÃ³n: CeretÃ©, CÃ³rdoba, Colombia

---

## ğŸ”— Enlaces Ãštiles

- [DocumentaciÃ³n de scikit-learn](https://scikit-learn.org/stable/documentation.html)
- [DocumentaciÃ³n de pandas](https://pandas.pydata.org/docs/)
- [Tutorial de Ãrboles de DecisiÃ³n](https://scikit-learn.org/stable/modules/tree.html)
- [Google Colab](https://colab.research.google.com/)

---

## ğŸ’¬ Contacto y Soporte

Para preguntas sobre el proyecto:
- ğŸ“§ Email: [Tu email]
- ğŸ”— GitHub: [Tu perfil]
- ğŸ“ UbicaciÃ³n: CeretÃ©, CÃ³rdoba, Colombia

---

## ğŸ“Œ Notas Importantes

âœ… **Datos:** 18.355 registros autÃ©nticos de clientes  
âœ… **Privacidad:** Datos depurados, sin informaciÃ³n sensible real  
âœ… **Reproducible:** Todo el cÃ³digo estÃ¡ documentado y comentado  
âœ… **AcadÃ©mico:** Citas completas de todas las fuentes  
âœ… **Profesional:** GrÃ¡ficas de alta resoluciÃ³n (300 DPI)  

---

## ğŸš€ PrÃ³ximos Pasos

1. **ImplementaciÃ³n en ProducciÃ³n**
   - IntegraciÃ³n con CRM de AW-Bikes
   - API REST para predicciones en tiempo real

2. **Extensiones del Modelo**
   - PredicciÃ³n de churn (clientes que dejarÃ¡n de comprar)
   - RecomendaciÃ³n de productos
   - DetecciÃ³n de fraude

3. **Mejoras Futuras**
   - Incorporar datos de redes sociales
   - Variables comportamentales
   - Factores estacionales

---

**Ãšltima actualizaciÃ³n:** 4 de diciembre de 2025  
**Status:** âœ… Completo y listo para producciÃ³n
